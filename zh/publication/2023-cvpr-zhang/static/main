<div class="container">
    <!-- Authors -->
    <div class="author-container">
        <div class="author">
            <a href="https://academic.davidz.cn/">
                <img class="image" src="https://avatars.githubusercontent.com/u/33928385" alt="Jiahao Zhang">
            </a>
            <a href="https://academic.davidz.cn/">Jiahao<br />Zhang</a><sup>1</sup>
        </div>
        <div class="author">
            <a href="https://users.cecs.anu.edu.au/~cherian/">
                <img class="image" src="https://avatars.githubusercontent.com/u/8115600" alt="Anoop Cherian">
            </a>
            <a href="https://users.cecs.anu.edu.au/~cherian/">Anoop<br />Cherian</a><sup>2</sup>
        </div>
        <div class="author">
            <a href="https://csyanbin.github.io/">
                <img class="image" src="https://csyanbin.github.io/img/yanbin.jpg" alt="Yanbin Liu">
            </a>
            <a href="https://csyanbin.github.io/">Yanbin<br />Liu</a><sup>1</sup>
        </div>
        <div class="author">
            <a href="https://www.itzikbs.com/">
                <img class="image" src="https://avatars.githubusercontent.com/u/13794171" alt="Yizhak Ben-Shabat">
            </a>
            <a href="https://www.itzikbs.com/">Yizhak<br />Ben-Shabat</a><sup>1,3</sup>
        </div>
        <div class="author">
            <a href="https://crodriguezo.me/">
                <img class="image" src="https://avatars.githubusercontent.com/u/3124475" alt="Cristian Rodriguez">
            </a>
            <a href="https://crodriguezo.me/">Cristian<br />Rodriguez</a><sup>4</sup>
        </div>
        <div class="author">
            <a href="https://users.cecs.anu.edu.au/~sgould/">
                <img class="image" src="https://avatars.githubusercontent.com/u/1948931" alt="Stephen Gould">
            </a>
            <a href="https://users.cecs.anu.edu.au/~sgould/">Stephen<br />Gould</a><sup>1</sup>
        </div>
    </div>
    <!-- Affiliations -->
    <div class="affiliation-container">
        <div><sup>1</sup><a href="https://www.anu.edu.au/">The Australian National University</a></div>
        <div><sup>2</sup><a href="https://www.merl.com/">Mitsubishi Electric Research Labs</a></div>
        <div style="width: 100%;"></div>
        <div><sup>3</sup><a href="https://www.technion.ac.il/en/home-2/">Technion Israel Institute of Technology</a>
        </div>
        <div><sup>4</sup><a href="https://www.adelaide.edu.au/aiml/">The Australian Institute for Machine Learning</a>
        </div>
    </div>
</div>

<!-- Rest (follow style from the theme) -->
<div class="article-container">
    <h3>Result Visualization</h3>
    <video autoplay controls muted loop>
        <source src="static/70350938_TEdm3OyeWjY_30fps.webm" type="video/webm">
    </video>
    <p><strong>Video 1.</strong> Video-diagram alignment between a YouTube video <a
            href="https://www.youtube.com/watch?v=TEdm3OyeWjY" target="_blank">TEdm3OyeWjY</a> and an Ikea furniture
        manual <a href="https://www.ikea.com/au/en/p/teodores-chair-white-70350938/" target="_blank">70350938</a>.</p>
    <video controls muted loop>
        <source src="static/60356219_moq_A1o3ZKw_30fps.webm" type="video/webm">
    </video>
    <p><strong>Video 2.</strong> Video-diagram alignment between a YouTube video <a
            href="https://www.youtube.com/watch?v=moq_A1o3ZKw" target="_blank">moq_A1o3ZKw</a> and an Ikea furniture
        manual <a href="https://www.ikea.com/au/en/p/rast-chest-of-3-drawers-pine-60356219/"
            target="_blank">60356219</a>.</p>
    <video controls muted loop>
        <source src="static/s29416013_l1OpqZcyoSI_30fps.webm" type="video/webm">
    </video>
    <p><strong>Video 3.</strong> Video-diagram alignment between a YouTube video <a
            href="https://www.youtube.com/watch?v=l1OpqZcyoSI" target="_blank">l1OpqZcyoSI</a> and an Ikea furniture
        manual <a href="https://www.ikea.com/au/en/p/oerfjaell-swivel-chair-white-vissle-light-grey-s29416013/"
            target="_blank">s29416013</a>.</p>
    <h3>Method</h3>
    <img src="static/method.svg" alt="Method" width="100%">
    <p class="caption"><strong>Figure 1.</strong> Visualization of our three losses described in Sec. 3.2. The intent is
        depicted in the first row and the batch formation in the second row. Loss (a) tries to pair video and image up
        across the entire dataset. Loss (b) only matches video clips and images corresponding to the same manual. And
        loss (c) push images from the same manual apart from each other for better feature discrimination.</p>
    <div class="subfigure">
        <div style="width: 78.7%; text-align: center;">
            <img src="static/model-training.svg" alt="Model Training" width="100%">
            <p class="caption">(1) Training Stage.</p>
        </div>
        <div style="width: 21.3%; text-align: center;">
            <img src="static/model-inference.svg" alt="Model Inference" width="100%">
            <p class="caption">(2) Inference Stage.</p>
        </div>
        <p class="caption"><strong>Figure 2.</strong> Schematic of our overall architecture. During training we
            extract features from each input video clip and set of instructional diagrams, respectively, using
            pre-trained encoders. We concatenate these with sinusoidal progress rate features (SPRF) introduced in
            Sec. 3.1 and project into the same D<sup>â„“</sup> dimensionality space. The matched video clip and
            instructional diagram feature pairs are used for Video-Diagram Contrastive Loss, the video clip feature
            and M instructional diagram features are fed into Video-Manual Contrastive Loss, and M instructional
            diagram features themselves are used in Intra-Manual Contrastive Loss introduced in Sec. 3.2. During
            inference all video features from N sequential video clips, and all M instructional diagram features
            from the corresponding manual are computed. We then form a similarity matrix and apply optimal transport
            (OT) introduced in Sec. 3.3 to produce the final alignment probabilities.</p>
    </div>
</div>
