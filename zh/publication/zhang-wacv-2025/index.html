<!doctype html><!-- This site was created with Hugo Blox. https://hugoblox.com --><!-- Last Published: 2024年10月29日 --><html lang=zh-Hans><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Hugo Blox Builder 5.9.7"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><script src=/js/mathjax-config.js></script>
<link rel=stylesheet href=/css/vendor-bundle.min.26c458e6907dc03073573976b7f4044e.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script>
<link rel=stylesheet href=/css/wowchemy.f6689966c0a10712f95f034011917db0.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="张家豪"><meta name=description content="这篇文章的主要研究对象是在视频中同时定位多个查询序列，尤其是将说明性图解与视频中的时间点对齐的问题。作者指出，现有的很多方法只针对单个查询进行定位，忽略了查询之间的内在关系（如互斥性和时间顺序），这可能导致不同步骤图解的时间跨度重叠或顺序错误，进而影响定位的准确性。为了应对这个问题，作者提出了一种新的方法，通过构造复合查询（将步骤图解的视觉内容特征与固定数量的可学习位置嵌入结合）来同时定位多个步骤图解。该方法通过自注意力机制减少时间跨度的重叠，并通过内容和位置的联合指导校正时间上的错位。文章展示了该方法在Ikea Assembly in the Wild（IAW）数据集和YouCook2基准数据集上的有效性，能够显著优于现有方法，同时能够同时定位多个查询。这种方法的核心贡献是设计了一种新的检测Transformer模型，能够同时定位一系列步骤图解，并通过复合查询和联合指导的交叉注意力机制提高定位准确性。 (ChatGPT4o)."><link rel=alternate hreflang=en href=https://academic.davidz.cn/en/publication/zhang-wacv-2025/><link rel=alternate hreflang=zh-hans href=https://academic.davidz.cn/zh/publication/zhang-wacv-2025/><link rel=canonical href=https://academic.davidz.cn/zh/publication/zhang-wacv-2025/><link rel=manifest href=/zh/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@academic-davidz"><meta property="twitter:creator" content="@academic-davidz"><meta property="twitter:image" content="https://academic.davidz.cn/zh/publication/zhang-wacv-2025/featured.png"><meta property="og:type" content="article"><meta property="og:site_name" content="Academic-DavidZ"><meta property="og:url" content="https://academic.davidz.cn/zh/publication/zhang-wacv-2025/"><meta property="og:title" content="Aligning Step-by-Step Instructional Diagrams to Video Demonstrations | Academic-DavidZ"><meta property="og:description" content="这篇文章的主要研究对象是在视频中同时定位多个查询序列，尤其是将说明性图解与视频中的时间点对齐的问题。作者指出，现有的很多方法只针对单个查询进行定位，忽略了查询之间的内在关系（如互斥性和时间顺序），这可能导致不同步骤图解的时间跨度重叠或顺序错误，进而影响定位的准确性。为了应对这个问题，作者提出了一种新的方法，通过构造复合查询（将步骤图解的视觉内容特征与固定数量的可学习位置嵌入结合）来同时定位多个步骤图解。该方法通过自注意力机制减少时间跨度的重叠，并通过内容和位置的联合指导校正时间上的错位。文章展示了该方法在Ikea Assembly in the Wild（IAW）数据集和YouCook2基准数据集上的有效性，能够显著优于现有方法，同时能够同时定位多个查询。这种方法的核心贡献是设计了一种新的检测Transformer模型，能够同时定位一系列步骤图解，并通过复合查询和联合指导的交叉注意力机制提高定位准确性。 (ChatGPT4o)."><meta property="og:image" content="https://academic.davidz.cn/zh/publication/zhang-wacv-2025/featured.png"><meta property="og:locale" content="zh-Hans"><meta property="article:published_time" content="2024-09-27T00:00:00+00:00"><meta property="article:modified_time" content="2024-09-27T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://academic.davidz.cn/zh/publication/zhang-wacv-2025/"},"headline":"Aligning Step-by-Step Instructional Diagrams to Video Demonstrations","image":["https://academic.davidz.cn/zh/publication/zhang-wacv-2025/featured.png"],"datePublished":"2024-09-27T00:00:00Z","dateModified":"2024-09-27T00:00:00Z","author":{"@type":"Person","name":"张家豪"},"publisher":{"@type":"Organization","name":"davidz.cn","logo":{"@type":"ImageObject","url":"https://academic.davidz.cn/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_3.png"}},"description":"这篇文章的主要研究对象是在视频中同时定位多个查询序列，尤其是将说明性图解与视频中的时间点对齐的问题。作者指出，现有的很多方法只针对单个查询进行定位，忽略了查询之间的内在关系（如互斥性和时间顺序），这可能导致不同步骤图解的时间跨度重叠或顺序错误，进而影响定位的准确性。为了应对这个问题，作者提出了一种新的方法，通过构造复合查询（将步骤图解的视觉内容特征与固定数量的可学习位置嵌入结合）来同时定位多个步骤图解。该方法通过自注意力机制减少时间跨度的重叠，并通过内容和位置的联合指导校正时间上的错位。文章展示了该方法在Ikea Assembly in the Wild（IAW）数据集和YouCook2基准数据集上的有效性，能够显著优于现有方法，同时能够同时定位多个查询。这种方法的核心贡献是设计了一种新的检测Transformer模型，能够同时定位一系列步骤图解，并通过复合查询和联合指导的交叉注意力机制提高定位准确性。 (ChatGPT4o)."}</script><title>Aligning Step-by-Step Instructional Diagrams to Video Demonstrations | Academic-DavidZ</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=28c3869a7d359f45833147eb8ad208ae><script src=/js/wowchemy-init.min.9e4214442a7711d35691acd58f6f6361.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>搜索</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=搜索... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=搜索...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/zh/>Academic-DavidZ</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label=切换导航>
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/zh/>Academic-DavidZ</a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/zh/#about><span>主页</span></a></li><li class=nav-item><a class=nav-link href=/zh/#featured><span>文章</span></a></li><li class=nav-item><a class=nav-link href=/zh/#projects><span>项目</span></a></li><li class=nav-item><a class=nav-link href=/zh/#experience><span>经历</span></a></li><li class=nav-item><a class=nav-link href=/zh/#accomplishments><span>获奖</span></a></li><li class=nav-item><a class=nav-link href=https://cv.davidz.cn/ target=_blank rel=noopener><span>简历</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=搜索><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>浅色</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>深色</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>自动</span></a></div></li><li class="nav-item dropdown i18n-dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true aria-label=语言><i class="fas fa-globe mr-1" aria-hidden=true></i><span class="d-none d-lg-inline">中文 (简体)</span></a><div class=dropdown-menu><div class="dropdown-item dropdown-item-active"><span>中文 (简体)</span></div><a class=dropdown-item href=https://academic.davidz.cn/en/publication/zhang-wacv-2025/><span>English</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class=pub><div class="article-container pt-3"><h1>Aligning Step-by-Step Instructional Diagrams to Video Demonstrations</h1><div class=article-metadata><div><span class=author-highlighted>张家豪</span>, <span>Frederic Zhang</span>, <span>Cristian Rodriguez</span>, <span>Yizhak Ben-Shabat</span>, <span>Anoop Cherian</span>, <span>Stephen Gould</span></div><span class=article-date>九月, 2024</span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=https://arxiv.org/pdf/2407.12066 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/zh/publication/zhang-wacv-2025/cite.bib>引用</a>
<a class="btn btn-outline-primary btn-page-header" href=https://arxiv.org/abs/2407.12066 target=_blank rel=noopener>ArXiv</a></div></div><div class="article-header container featured-image-wrapper mt-4 mb-4" style=max-width:1200px;max-height:400px><div style=position:relative><img src=/zh/publication/zhang-wacv-2025/featured_huf33ce902d26e13d5970a88b7113bb1eb_1108386_9c7fc8853f21816583498d684c6b3174.webp width=1200 height=400 alt class=featured-image>
<span class=article-header-caption>An illustration of the temporal instructional diagram grounding task between a YouTube video (top) <a href="https://www.youtube.com/watch?v=xPNkHAii3fU" target=_blank rel=noopener>xPNkHAii3fU</a> and an Ikea furniture manual (bottom) <a href=https://www.ikea.com/au/en/p/hemnes-bookcase-white-stain-00352894/ target=_blank rel=noopener>00352894</a>. This task aims to predict the start and end timestamps for all step diagrams simultaneously.</span></div></div><div class=article-container><h3>摘要</h3><p class=pub-abstract>We study the challenging problem of simultaneously localizing a sequence of queries in the form of instructional diagrams in a video. This requires understanding not only the individual queries but also their interrelationships. However, most existing methods focus on grounding one query at a time, ignoring the inherent structures among queries such as the general mutual exclusiveness and the temporal order. Consequently, the predicted timespans of different step diagrams may overlap considerably or violate the temporal order, thus harming the accuracy. In this paper, we tackle this issue by simultaneously grounding a sequence of step diagrams. Specifically, we propose composite queries, constructed by exhaustively pairing up the visual content features of the step diagrams and a fixed number of learnable positional embeddings. Our insight is that self-attention among composite queries carrying different content features suppress each other to reduce timespan overlaps in predictions, while the cross-attention corrects the temporal misalignment via content and position joint guidance. We demonstrate the effectiveness of our approach on the IAW dataset for grounding step diagrams and the YouCook2 benchmark for grounding natural language queries, significantly outperforming existing methods while simultaneously grounding multiple queries.</p><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">类型</div><div class="col-12 col-md-9"><a href=/zh/publication/#1>1</a></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">出版物</div><div class="col-12 col-md-9">In <em>Winter Conference on Applications of Computer Vision 2025</em></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=space-below></div><div class=article-style></div><div class=article-tags><a class="badge badge-light" href=/zh/tag/deep-learning/>Deep Learning</a></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Facademic.davidz.cn%2Fzh%2Fpublication%2Fzhang-wacv-2025%2F&amp;text=Aligning+Step-by-Step+Instructional+Diagrams+to+Video+Demonstrations" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Facademic.davidz.cn%2Fzh%2Fpublication%2Fzhang-wacv-2025%2F&amp;t=Aligning+Step-by-Step+Instructional+Diagrams+to+Video+Demonstrations" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Aligning%20Step-by-Step%20Instructional%20Diagrams%20to%20Video%20Demonstrations&amp;body=https%3A%2F%2Facademic.davidz.cn%2Fzh%2Fpublication%2Fzhang-wacv-2025%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Facademic.davidz.cn%2Fzh%2Fpublication%2Fzhang-wacv-2025%2F&amp;title=Aligning+Step-by-Step+Instructional+Diagrams+to+Video+Demonstrations" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Aligning+Step-by-Step+Instructional+Diagrams+to+Video+Demonstrations%20https%3A%2F%2Facademic.davidz.cn%2Fzh%2Fpublication%2Fzhang-wacv-2025%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Facademic.davidz.cn%2Fzh%2Fpublication%2Fzhang-wacv-2025%2F&amp;title=Aligning+Step-by-Step+Instructional+Diagrams+to+Video+Demonstrations" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=https://academic.davidz.cn/><img class="avatar mr-3 avatar-circle" src=/zh/authors/admin/avatar_hu07296352858a158ff337e5cb9d784453_95701_270x270_fill_q75_lanczos_center.jpg alt=张家豪></a><div class=media-body><h5 class=card-title><a href=https://academic.davidz.cn/>张家豪</a></h5><h6 class=card-subtitle>博士研究生</h6><p class=card-text>研究方向：深度学习，计算机视觉以及网页开发。</p><ul class=network-icon aria-hidden=true><li><a href=mailto:jiahao.zhang@anu.edu.au><i class="fas fa-envelope"></i></a></li><li><a href=https://blog.davidz.cn target=_blank rel=noopener><i class="fas fa-blog"></i></a></li><li><a href=https://github.com/DavidZhang73 target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href="https://scholar.google.co.uk/citations?user=r040KUgAAAAJ" target=_blank rel=noopener><i class="fas fa-graduation-cap"></i></a></li><li><a href=https://cv.davidz.cn target=_blank rel=noopener><i class="ai ai-cv"></i></a></li></ul></div></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2024 DavidZ. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>由<a href="https://hugoblox.com/?utm_campaign=poweredby" target=_blank rel=noopener>Hugo Blox Builder</a>支持发布——免费<a href=https://github.com/HugoBlox/hugo-blox-builder target=_blank rel=noopener>开源</a>网站，为创作者赋能。</p></footer></div></div><script src=/js/vendor-bundle.min.f64289d8217e08e3afcd597d60836062.js></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script>
<script src=/zh/js/wowchemy.min.969c059ff7aed5c4de7aa0431d7a9a30.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>引用</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> 复制</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> 下载</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.9137013a66774049159934c29c3f0205.js type=module></script>
<script async defer data-website-id=78221282-8049-4f9e-9010-ee8baa093965 src=https://umami.davidz.cn/script.js></script></body></html>