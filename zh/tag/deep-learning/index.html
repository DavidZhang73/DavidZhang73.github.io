<!doctype html><!-- This site was created with Hugo Blox. https://hugoblox.com --><!-- Last Published: 2024年10月4日 --><html lang=zh-Hans><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Hugo Blox Builder 5.9.7"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><script src=/js/mathjax-config.js></script>
<link rel=stylesheet href=/css/vendor-bundle.min.26c458e6907dc03073573976b7f4044e.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script>
<link rel=stylesheet href=/css/wowchemy.f6689966c0a10712f95f034011917db0.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="张家豪"><meta name=description content="Academic Page abouth Jiahao Zhang"><link rel=alternate hreflang=en href=https://academic.davidz.cn/en/tag/deep-learning/><link rel=alternate hreflang=zh-hans href=https://academic.davidz.cn/zh/tag/deep-learning/><link rel=canonical href=https://academic.davidz.cn/zh/tag/deep-learning/><link rel=manifest href=/zh/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@academic-davidz"><meta property="twitter:creator" content="@academic-davidz"><meta property="twitter:image" content="https://academic.davidz.cn/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png"><meta property="og:type" content="website"><meta property="og:site_name" content="Academic-DavidZ"><meta property="og:url" content="https://academic.davidz.cn/zh/tag/deep-learning/"><meta property="og:title" content="Deep Learning | Academic-DavidZ"><meta property="og:description" content="Academic Page abouth Jiahao Zhang"><meta property="og:image" content="https://academic.davidz.cn/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="zh-Hans"><meta property="og:updated_time" content="2024-09-27T00:00:00+00:00"><link rel=alternate href=/zh/tag/deep-learning/index.xml type=application/rss+xml title=Academic-DavidZ><title>Deep Learning | Academic-DavidZ</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper><script src=/js/wowchemy-init.min.9e4214442a7711d35691acd58f6f6361.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>搜索</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=搜索... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=搜索...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/zh/>Academic-DavidZ</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label=切换导航>
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/zh/>Academic-DavidZ</a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/zh/#about><span>主页</span></a></li><li class=nav-item><a class=nav-link href=/zh/#featured><span>文章</span></a></li><li class=nav-item><a class=nav-link href=/zh/#projects><span>项目</span></a></li><li class=nav-item><a class=nav-link href=/zh/#experience><span>经历</span></a></li><li class=nav-item><a class=nav-link href=/zh/#accomplishments><span>获奖</span></a></li><li class=nav-item><a class=nav-link href=https://cv.davidz.cn/ target=_blank rel=noopener><span>简历</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=搜索><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>浅色</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>深色</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>自动</span></a></div></li><li class="nav-item dropdown i18n-dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true aria-label=语言><i class="fas fa-globe mr-1" aria-hidden=true></i><span class="d-none d-lg-inline">中文 (简体)</span></a><div class=dropdown-menu><div class="dropdown-item dropdown-item-active"><span>中文 (简体)</span></div><a class=dropdown-item href=https://academic.davidz.cn/en/tag/deep-learning/><span>English</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class="universal-wrapper pt-3"><h1>Deep Learning</h1></div><div class=universal-wrapper><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/zh/publication/zhang-wacv-2025/>Aligning Step-by-Step Instructional Diagrams to Video Demonstrations</a></div><a href=/zh/publication/zhang-wacv-2025/ class=summary-link><div class=article-style>The paper &ldquo;Temporally Grounding Instructional Diagrams in Unconstrained Videos&rdquo; introduces a method for simultaneously localizing multiple instructional diagram queries in videos, addressing the limitations of current approaches that handle queries individually. The proposed method uses composite queries combining visual features and positional embeddings, reducing overlaps and correcting temporal misalignment. Tested on the IAW and YouCook2 datasets, this approach significantly improves grounding accuracy by leveraging self-attention and cross-attention mechanisms, outperforming existing methods while maintaining the temporal structure of instructional steps. (Generated by ChatGPT4o).</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted>张家豪</span>, <span>Anoop Cherian</span>, <span>Frederic Zhang</span>, <span>Cristian Rodriguez</span>, <span>Yizhak Ben-Shabat</span>, <span>Stephen Gould</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/pdf/2407.12066 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/zh/publication/zhang-wacv-2025/cite.bib>引用</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2407.12066 target=_blank rel=noopener>ArXiv</a></div></div><div class=ml-3><a href=/zh/publication/zhang-wacv-2025/><img src=/zh/publication/zhang-wacv-2025/featured_huf33ce902d26e13d5970a88b7113bb1eb_1108386_d00a7f6351b1a2efd43fc3606d819355.webp height=50 width=150 alt="Aligning Step-by-Step Instructional Diagrams to Video Demonstrations" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=https://github.com/DavidZhang73/AssemblyVideoManualAlignment target=_blank rel=noopener>Assembly Video Manual Alignment</a></div><a href=https://github.com/DavidZhang73/AssemblyVideoManualAlignment target=_blank rel=noopener class=summary-link><div class=article-style>CVPR'23 Aligning Step-by-Step Instructional Diagrams to Video Demonstrations的官方Pytorch实现。</div></a><div class="stream-meta article-metadata"></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/DavidZhang73/AssemblyVideoManualAlignment target=_blank rel=noopener>代码</a></div></div><div class=ml-3><a href=https://github.com/DavidZhang73/AssemblyVideoManualAlignment target=_blank rel=noopener><img src=/zh/project/assembly-video-manual-alignment/featured_hu47d4830ae752520931f9bd070df3961b_714524_8449d61bcb7c13488714d3668b9f074c.webp height=66 width=150 alt="Assembly Video Manual Alignment" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/zh/publication/zhang-cvpr-2023/>Aligning Step-by-Step Instructional Diagrams to Video Demonstrations</a></div><a href=/zh/publication/zhang-cvpr-2023/ class=summary-link><div class=article-style>本文讨论了一种新颖的设置，其中指令步骤以装配图的形式表示，并与来自野外视频的片段进行对齐。作者引入了一种监督对比学习方法，该方法学习将视频与装配图的细微细节对齐，由一组新颖的损失指导。他们还引入了一个新的数据集：IAW-用于宜家野外装配-包括来自不同家具装配集合的183小时视频和近8,300幅来自相关说明手册的插图，并注释了其地面真实对齐。作者在此数据集上定义了两个任务：首先，在视频片段和插图之间进行最近邻检索；其次，将指令步骤和每个视频的片段对齐。在IAW上进行的广泛实验表明，我们的方法相对于替代方案具有优越的性能。(由 New Bing 生成).</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted>张家豪</span>, <span>Anoop Cherian</span>, <span>刘彦斌</span>, <span>Yizhak Ben-Shabat</span>, <span>Cristian Rodriguez</span>, <span>Stephen Gould</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Aligning_Step-by-Step_Instructional_Diagrams_to_Video_Demonstrations_CVPR_2023_paper.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/zh/publication/zhang-cvpr-2023/cite.bib>引用</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/DavidZhang73/AssemblyVideoManualAlignment target=_blank rel=noopener>代码</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://iaw.davidz.cn target=_blank rel=noopener>数据集</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://academic.davidz.cn/en/publication/zhang-cvpr-2023/ target=_blank rel=noopener>项目</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://cvpr2023.thecvf.com/media/PosterPDFs/CVPR%202023/22280.png target=_blank rel=noopener>海报</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://cvpr2023.thecvf.com/media/cvpr-2023/Slides/22280.pdf target=_blank rel=noopener>演示文稿</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=8iC5QyP8U6o" target=_blank rel=noopener>视频</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2303.13800 target=_blank rel=noopener>ArXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/zh/publication/zhang-cvpr-2023/supplementary.pdf>补充材料</a></div></div><div class=ml-3><a href=/zh/publication/zhang-cvpr-2023/><img src=/zh/publication/zhang-cvpr-2023/featured_hu47d4830ae752520931f9bd070df3961b_714524_8449d61bcb7c13488714d3668b9f074c.webp height=66 width=150 alt="Aligning Step-by-Step Instructional Diagrams to Video Demonstrations" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/zh/publication/zhuang-iros-2022/>GoferBot: A Visual Guided Human-Robot Collaborative Assembly System</a></div><a href=/zh/publication/zhuang-iros-2022/ class=summary-link><div class=article-style>GoferBot is a novel assembly system that seamlessly integrates all sub-modules by utilising implicit semantic information purely from visual perception.</div></a><div class="stream-meta article-metadata"><div><span>庄哲宇</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title=相同贡献></i>, <span>Yizhak Ben-Shabat</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title=相同贡献></i>, <span class=author-highlighted>张家豪</span>, <span>Stephen Gould</span>, <span>Robert Mahony</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://ieeexplore.ieee.org/abstract/document/9981122 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/zh/publication/zhuang-iros-2022/cite.bib>引用</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=Fo5XI5OJ4QQ" target=_blank rel=noopener>视频</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/10.1109/IROS47612.2022.9981122 target=_blank rel=noopener>DOI</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2304.08840 target=_blank rel=noopener>ArXiv</a></div></div><div class=ml-3><a href=/zh/publication/zhuang-iros-2022/><img src=/zh/publication/zhuang-iros-2022/featured_hud7e3312f6e9bc8cbce5bc5e91c849d57_8860161_015d8978676e0e1d2c02905e7a76933f.webp height=79 width=150 alt="GoferBot: A Visual Guided Human-Robot Collaborative Assembly System" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=https://github.com/DavidZhang73/ImageCaptionGenerator target=_blank rel=noopener>Image Caption Generator</a></div><a href=https://github.com/DavidZhang73/ImageCaptionGenerator target=_blank rel=noopener class=summary-link><div class=article-style>一个基于 encoder(Resnet152)-decoder(LSTM) 的图像描述模型实现。</div></a><div class="stream-meta article-metadata"></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/DavidZhang73/ImageCaptionGenerator target=_blank rel=noopener>代码</a></div></div><div class=ml-3><a href=https://github.com/DavidZhang73/ImageCaptionGenerator target=_blank rel=noopener><img src=/zh/project/image-caption-generator/featured_hua9b8deec36d6892c209521dce5147c5a_251706_2215208a5f1a6573b3e5e1fdda5a2d63.webp height=69 width=150 alt="Image Caption Generator" loading=lazy></a></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2024 DavidZ. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>由<a href="https://hugoblox.com/?utm_campaign=poweredby" target=_blank rel=noopener>Hugo Blox Builder</a>支持发布——免费<a href=https://github.com/HugoBlox/hugo-blox-builder target=_blank rel=noopener>开源</a>网站，为创作者赋能。</p></footer></div></div><script src=/js/vendor-bundle.min.f64289d8217e08e3afcd597d60836062.js></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script>
<script src=/zh/js/wowchemy.min.969c059ff7aed5c4de7aa0431d7a9a30.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>引用</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> 复制</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> 下载</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.9137013a66774049159934c29c3f0205.js type=module></script>
<script async defer data-website-id=78221282-8049-4f9e-9010-ee8baa093965 src=https://umami.davidz.cn/script.js></script></body></html>